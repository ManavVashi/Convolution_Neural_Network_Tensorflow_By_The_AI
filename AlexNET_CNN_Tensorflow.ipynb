{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**below code is for importing dataset from kaggle to colab.**"
      ],
      "metadata": {
        "id": "ieQCRgcra-v2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvrRsxSb1YPh",
        "outputId": "7d01510c-7361-4bf9-f777-739571ed58bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat 'kaggle.json': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d salader/dogs-vs-cats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaBi84lm39xQ",
        "outputId": "67b0ce6f-43d5-43e6-dd2b-5d5e5be134db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/salader/dogs-vs-cats\n",
            "License(s): unknown\n",
            "Downloading dogs-vs-cats.zip to /content\n",
            " 99% 1.05G/1.06G [00:06<00:00, 125MB/s]\n",
            "100% 1.06G/1.06G [00:06<00:00, 176MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/dogs-vs-cats.zip', 'r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "gwh4w45Y4AvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**above code is for importing dataset from kaggle to colab.**"
      ],
      "metadata": {
        "id": "VwMvF_Z4bK9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "mYbkvM0_4DVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_valid_test_generator=ImageDataGenerator(rescale=1./255.0,\n",
        "                                         validation_split=0.2)\n",
        "\n",
        "#rescalling and validation split setting"
      ],
      "metadata": {
        "id": "y0bowOb74IbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data=train_valid_test_generator.flow_from_directory(directory='/content/train',\n",
        "                                                     class_mode='binary',\n",
        "                                                     color_mode='rgb',\n",
        "                                                     target_size=(256,256),\n",
        "                                                     batch_size=128,\n",
        "                                                     subset='training',\n",
        "                                                     shuffle=False)\n",
        "\n",
        "validation_data=train_valid_test_generator.flow_from_directory(directory='/content/train',\n",
        "                                                                class_mode='binary',\n",
        "                                                                color_mode='rgb',\n",
        "                                                                target_size=(256,256),\n",
        "                                                                batch_size=32,\n",
        "                                                                subset='validation',\n",
        "                                                                shuffle=False)\n",
        "\n",
        "test_data=train_valid_test_generator.flow_from_directory(directory='/content/test',\n",
        "                                                         class_mode='binary',\n",
        "                                                         color_mode='rgb',\n",
        "                                                         target_size=(256,256))\n",
        "\n",
        "#initiating hyperperameters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eA6yka7g4L4o",
        "outputId": "2fa3057e-7fa1-46f8-9d85-bdd2076fbb59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 16000 images belonging to 2 classes.\n",
            "Found 4000 images belonging to 2 classes.\n",
            "Found 5000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Sequential\n",
        "from keras.layers import Conv2D,MaxPool2D,Flatten,Dense,Dropout\n",
        "\n",
        "#importing layers"
      ],
      "metadata": {
        "id": "-Uj79Ll04O9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=96,kernel_size=11,strides=4,padding='valid',activation='relu',input_shape=(256,256,3)))\n",
        "model.add(MaxPool2D(pool_size=3,strides=2,padding='valid'))\n",
        "\n",
        "model.add(Conv2D(filters=256,kernel_size=5,strides=1,padding='same',activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=3,strides=2,padding='valid'))\n",
        "\n",
        "model.add(Conv2D(filters=384,kernel_size=3,strides=1,padding='same',activation='relu'))\n",
        "\n",
        "model.add(Conv2D(filters=384,kernel_size=3,strides=1,padding='same',activation='relu'))\n",
        "\n",
        "model.add(Conv2D(filters=256,kernel_size=3,strides=1,padding='same',activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=3,strides=2,padding='valid'))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(units=4096,activation='relu'))\n",
        "\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Dense(units=4096,activation='relu'))\n",
        "\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Dense(units=1,activation='softmax'))\n",
        "\n",
        "#AlexNET model architecture"
      ],
      "metadata": {
        "id": "qhXlWykn4Rlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIMe0jDB7m-b",
        "outputId": "9764fbb8-38bd-4a10-cf74-cbe57e96e1fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 62, 62, 96)        34944     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 30, 30, 96)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 26, 26, 256)       614656    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 12, 12, 256)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 10, 10, 384)       885120    \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 8, 8, 384)         1327488   \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 6, 6, 256)         884992    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 2, 2, 256)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4096)              4198400   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 4097      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24731009 (94.34 MB)\n",
            "Trainable params: 24731009 (94.34 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "vwyjBCAf8x78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(train_data,validation_data=validation_data,epochs=10)\n",
        "\n",
        "#model training"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OgrfgQa84nT",
        "outputId": "ccd4dd0c-13f7-4fc4-c5b7-1c1cad6fc4a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "500/500 [==============================] - 59s 100ms/step - loss: 1.1818 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 2/8\n",
            "500/500 [==============================] - 49s 98ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 3/8\n",
            "500/500 [==============================] - 49s 97ms/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 4/8\n",
            "500/500 [==============================] - 50s 101ms/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 5/8\n",
            "500/500 [==============================] - 50s 99ms/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 6/8\n",
            "500/500 [==============================] - 48s 96ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 7/8\n",
            "500/500 [==============================] - 49s 98ms/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 8/8\n",
            "500/500 [==============================] - 51s 101ms/step - loss: 0.6935 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history[\"accuracy\"])\n",
        "plt.plot(history.history[\"val_accuracy\"])\n",
        "\n",
        "#visulizing graph of training accuracy v/s epochs and validation accuracy v/s epochs"
      ],
      "metadata": {
        "id": "1HtjtgpbAv8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history[\"loss\"])\n",
        "plt.plot(history.history[\"val_loss\"])\n",
        "\n",
        "#visulizing graph between training loss v/s epochs and validation loss v/s epochs"
      ],
      "metadata": {
        "id": "a_yWiHVIA3UP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **For Theory,**\n",
        "* You can refer below blog. This blog is not written by me but it is such a nice and well maintained and well defined blog that capable to teach us how things are work?? I think if this type of content available for this topic then why I should remake it and waste my time. This is my thinking behind this.\n",
        "\n",
        "https://medium.com/@siddheshb008/alexnet-architecture-explained-b6240c528bd5"
      ],
      "metadata": {
        "id": "IVcdZyRSd8gD"
      }
    }
  ]
}